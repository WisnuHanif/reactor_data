{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing research data\n",
    "https://github.com/WisnuHanif/reactor_data/blob/main/reactor_data.csv'\n",
    "prep0 = pd.read_csv('https://raw.githubusercontent.com/WisnuHanif/reactor_data/main/reactor_data.csv')\n",
    "prep0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identity variables name\n",
    "prep0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing variable description & 'NO', 'Time' column\n",
    "prep1 = prep0.iloc[1:, :].drop(['Running_cycle','Time'], axis=1)\n",
    "prep1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert timestamp object data to numerical\n",
    "prep2 = prep1.apply(pd.to_numeric)\n",
    "print(prep2.dtypes, prep2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there's missing value\n",
    "prep2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing data where plant is not run, by identifying total raw material 'FI-001' loss flow rate\n",
    "import seaborn as sns\n",
    "sns.boxplot(data=prep2,x=prep2['FI-001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove shut down data by identifying outlier FI-001 with Inter Quantile Range Method\n",
    "\n",
    "from numpy import percentile\n",
    "# calculate interquartile range\n",
    "q25_a, q75_a = percentile(prep2['FI-001'], 25), percentile(prep2['FI-001'], 75)\n",
    "iqr_a = q75_a - q25_a\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25_a, q75_a, iqr_a))\n",
    "# calculate the outlier cutoff\n",
    "cut_off_a = iqr_a * 1.5\n",
    "lower_a, upper_a = q25_a - cut_off_a, q75_a + cut_off_a\n",
    "print('Lower whisker=%.2f, Upper whisker=%.2f' % (lower_a, upper_a))\n",
    "# identify outliers\n",
    "shut_down_data = prep2[(prep2['FI-001']<lower_a)|(prep2['FI-001']>upper_a)]\n",
    "print('Shut down data: %d' % len(shut_down_data))\n",
    "# remove outliers\n",
    "shut_down_removed = prep2[(prep2['FI-001']>lower_a)&(prep2['FI-001']<upper_a)]\n",
    "print('Non-Shut down data: %d' % len(shut_down_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check again if there's still outlier in 'FI-001'\n",
    "sns.boxplot(data=shut_down_removed, x=shut_down_removed['FI-001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep3 = shut_down_removed\n",
    "prep3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outlier for all variables while keeps the whole row intact\n",
    "lb = prep3.quantile(0.01)\n",
    "ub = prep3.quantile(0.99)\n",
    "\n",
    "prep4 = prep3[(prep3 > lb) & (prep3 < ub)]\n",
    "prep4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check deleted value position\n",
    "import missingno as mno\n",
    "mno.matrix(prep4, figsize = (20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Correlation matrix between variables before missing value imputation\n",
    "#corr = prep4.corr()\n",
    "#corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr.values[np.triu_indices_from(corr.values,1)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing value (from removed outlier) with imputer\n",
    "prep5 = prep4.interpolate(method ='linear', limit_direction ='forward')\n",
    "prep5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep5.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep5.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Correlation matrix after data imputation\n",
    "corr2 = prep5.corr()\n",
    "corr2.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization plot for all variables\n",
    "#group_1 = prep5.iloc[:,0:9]\n",
    "#group_2 = prep5.iloc[:,9:18]\n",
    "#group_3 = prep5.iloc[:,18:27]\n",
    "#group_4 = prep5.iloc[:,27:36]\n",
    "#group_5 = prep5.iloc[:,36:45]\n",
    "#group_6 = prep5.iloc[:,45:54]\n",
    "#group_7 = prep5.iloc[:,54:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot for group 1\n",
    "#group_1.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 2\n",
    "#group_2.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 3\n",
    "#group_3.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 4\n",
    "#group_4.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 5\n",
    "#group_5.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 6\n",
    "#group_6.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 7\n",
    "#group_7.plot(subplots =True, sharex = True, figsize = (40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation coefficient\n",
    "select_corr = prep5.corr()[\"CONVERSION\"].sort_values(ascending=False)[1:]\n",
    "\n",
    "# absolute for positive values\n",
    "abs_corr = abs(select_corr)\n",
    "\n",
    "# random threshold for features to keep\n",
    "selected_features = abs_corr[abs_corr>0.4]\n",
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop low correlation features\n",
    "prep6 = prep5[selected_features.index].interpolate(method ='linear', limit_direction ='backward')\n",
    "prep6.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = prep5[\"CONVERSION\"]\n",
    "X = prep6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove collinearity by removing irrelavant features with ebbedded method\n",
    "from sklearn.linear_model import LassoCV\n",
    "reg = LassoCV()\n",
    "reg.fit(X, y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X,y))\n",
    "coef = pd.Series(reg.coef_, index = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize important feature\n",
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select relevant reatures\n",
    "abs_coef = abs(coef)\n",
    "relevant_features = abs_coef[abs_coef>0]\n",
    "prep7 = prep6[relevant_features.index].sort_index(axis=1, ascending=True)\n",
    "prep7['CONVERSION'] = prep5[\"CONVERSION\"]\n",
    "prep7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr3 = prep7.corr().style.background_gradient(cmap='coolwarm')\n",
    "corr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Scaling with normalization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# transform data\n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(prep7), columns = prep7.columns)\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = prep7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING MODEL : RANDOM FORREST REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_data = data\n",
    "#Import the features\n",
    "features = data.drop('CONVERSION', axis = 1)\n",
    "# Extract the labels\n",
    "targets = data['CONVERSION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(features.columns)\n",
    "feature_names = features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#Create split data for targets\n",
    "train_targets_size = int(len(targets) * 0.8)\n",
    "train_targets, test_targets = targets[0:train_targets_size], targets[train_targets_size:len(targets)]\n",
    "print('Observations: %d' % (len(targets)))\n",
    "print('Training Observations: %d' % (len(train_targets)))\n",
    "print('Testing Observations: %d' % (len(test_targets)))\n",
    "plt.plot(train_targets)\n",
    "plt.plot([None for i in train_targets] + [x for x in test_targets])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create split data for features\n",
    "train_features_size = int(len(features) * 0.8)\n",
    "train_features, test_features = features[0:train_features_size], features[train_features_size:len(features)]\n",
    "print('Observations: %d' % (len(features)))\n",
    "print('Training Observations: %d' % (len(train_features)))\n",
    "print('Testing Observations: %d' % (len(test_features)))\n",
    "#plt.plot(train_features)\n",
    "#plt.plot([None for i in train_features] + [x for x in test_features])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_targets.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation of missing values\n",
    "train_features = train_features.fillna(train_features.mean())\n",
    "test_features = test_features.fillna(test_features.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Ramdom Forest Regressor without hyper parameter tuning (default)\n",
    "%timeit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, oob_score = True)\n",
    "regressor.fit(train_features, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Regressor score and OOB Score of the model\n",
    "print(\"\\nRegressor Score \" + str(regressor.score(train_features, train_targets)), \"\\nOOB Score \" + str(regressor.oob_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = []\n",
    "max_depths = []\n",
    "\n",
    "# Stats about the trees in random forest\n",
    "for ind_tree in regressor.estimators_:\n",
    "    n_nodes.append(ind_tree.tree_.node_count)\n",
    "    max_depths.append(ind_tree.tree_.max_depth)\n",
    "    \n",
    "print(f'Average number of nodes {int(np.mean(n_nodes))}')\n",
    "print(f'Average maximum depth {int(np.mean(max_depths))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(test_features)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_targets, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_targets, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_targets, y_pred)))\n",
    "print('Coefficient of Determination:', r2_score(test_targets, y_pred)) \n",
    "print('Accuracy:', 100 - (100 * np.mean((abs(y_pred - test_targets)) / test_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets = test_targets.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs prediction\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.figure()\n",
    "    plt.plot(test_targets, label = \"Actual Conversion\")\n",
    "    plt.plot(y_pred, label = \"Prediction\")\n",
    "    plt.title('Random Forrest Regression Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Conversion (%)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - test_targets)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'feature': feature_list,\n",
    "                   'importance': regressor.feature_importances_}).\\\n",
    "                    sort_values('importance', ascending = False)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Search with Cross Validation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 100, num = 19)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, scoring='neg_mean_absolute_error', \n",
    "                              cv = 4, verbose=2, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(train_features, train_targets);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "best_pred = best_random.predict(test_features)\n",
    "best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Best Random Search Model\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_targets, best_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_targets, best_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_targets, best_pred)))\n",
    "print('Coefficient of Determination:', r2_score(test_targets, best_pred)) \n",
    "print('Accuracy:', 100 - (100 * np.mean((abs(best_pred - test_targets)) / test_targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Curves\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "tree_grid = {'n_estimators': [int(x) for x in np.linspace(1, 301, 30)]}\n",
    "\n",
    "# Create the grid search model and fit to the training data\n",
    "tree_grid_search = GridSearchCV(best_random, param_grid=tree_grid, verbose = 2, n_jobs=-1, cv = 4,\n",
    "                                scoring = 'neg_mean_absolute_error')\n",
    "tree_grid_search.fit(train_features, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs prediction\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.figure()\n",
    "    plt.plot(test_targets, label = \"Actual Conversion\")\n",
    "    plt.plot(best_pred, label = \"Prediction\")\n",
    "    plt.title('Random Forrest Regression Prediction (Best Parameter Tuning)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Conversion (%)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = rf_random.cv_results_['mean_train_score']\n",
    "len(train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, param = 'n_estimators', name = 'Num Trees'):\n",
    "    param_name = 'param_%s' % param\n",
    "\n",
    "    # Extract information from the cross validation model\n",
    "    #train_scores = model.cv_results_['mean_train_score']\n",
    "    test_scores = model.cv_results_['mean_test_score']\n",
    "    train_time = model.cv_results_['mean_fit_time']\n",
    "    param_values = list(model.cv_results_[param_name])\n",
    "    \n",
    "    # Plot the scores over the parameter\n",
    "    plt.subplots(1, 2, figsize=(10, 6))\n",
    "    plt.subplot(121)\n",
    "    #plt.plot(param_values, train_scores, 'bo-', label = 'train')\n",
    "    plt.plot(param_values, test_scores, 'go-', label = 'test')\n",
    "    plt.ylim(ymin = -2.5, ymax = 0)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Neg Mean Absolute Error')\n",
    "    plt.title('Score vs %s' % name)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(param_values, train_time, 'ro-')\n",
    "    plt.ylim(ymin = 0.0, ymax = 40.0)\n",
    "    plt.grid()\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Train Time (sec)')\n",
    "    plt.title('Training Time vs %s' % name)\n",
    "    \n",
    "    \n",
    "    plt.tight_layout(pad = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(tree_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING MODEL : SUPPORT VECTOR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Select scaled data\n",
    "svr_data = scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. import data for SVR\n",
    "\n",
    "x = svr_data.drop('CONVERSION', axis = 1).values.astype(float).reshape(-1, 16)\n",
    "y = svr_data['CONVERSION'].values.astype(float)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "#Create split data for targets\n",
    "y_train_size = int(len(y) * 0.8)\n",
    "y_train, y_test = y[0:y_train_size], y[y_train_size:len(y)]\n",
    "print('Observations: %d' % (len(y)))\n",
    "print('Training Observations: %d' % (len(y_train)))\n",
    "print('Testing Observations: %d' % (len(y_test)))\n",
    "plt.plot(y_train)\n",
    "plt.plot([None for i in y_train] + [x for x in y_test])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create split data for features\n",
    "x_train_size = int(len(x) * 0.8)\n",
    "x_train, x_test = x[0:x_train_size], x[x_train_size:len(x)]\n",
    "print('Observations: %d' % (len(x)))\n",
    "print('Training Observations: %d' % (len(x_train)))\n",
    "print('Testing Observations: %d' % (len(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', x_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', x_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel = 'rbf')\n",
    "svr_rbf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_pred = svr_rbf.predict(x_test)\n",
    "svr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating SVR performance\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import r2_score \n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, svr_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, svr_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, svr_pred)))\n",
    "print('Coefficient of Determination:', r2_score(y_test, svr_pred)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs prediction\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.figure()\n",
    "    plt.plot(y_test, label = \"Actual Conversion\")\n",
    "    plt.plot(svr_pred, label = \"Prediction\")\n",
    "    plt.title('Support Vector Regression Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Conversion (%)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR polynomial kernel with 3 degree\n",
    "svr_poly3 = SVR(kernel='poly', gamma='auto', degree=3)\n",
    "#SVR polynomial kernel with 4 degree\n",
    "svr_poly4 = SVR(kernel='poly', gamma='auto', degree=4)\n",
    "#SVR polynomial kernel with 5 degree\n",
    "svr_poly5 = SVR(kernel='poly', gamma='auto', degree=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svrs = [svr_rbf, svr_poly3, svr_poly4, svr_poly5]\n",
    "kernel_label = ['rbf', '3 degree Polynomial', '4 degree Polynomial', '5 degree Polynomial']\n",
    "fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(10, 10), sharey=True)\n",
    "for ix, svr in enumerate(svrs):\n",
    "    svr.fit(x_train, y_train)\n",
    "    svr_poly_pred = svr.predict(x_test)\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, svr_poly_pred))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(y_test, svr_poly_pred))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, svr_poly_pred)))\n",
    "    print('Coefficient of Determination:', r2_score(y_test, svr_poly_pred)) \n",
    "    with plt.style.context('ggplot'):\n",
    "        axes[ix].plot(y_test, label = \"Actual Conversion\")\n",
    "        axes[ix].plot(svr_poly_pred,\n",
    "                  label='{} model'.format(kernel_label[ix]))\n",
    "        axes[ix].legend(loc='upper center', bbox_to_anchor=(0.5, 1.1),\n",
    "                    ncol=1, fancybox=True, shadow=True)\n",
    "        axes[ix].legend(loc='best')\n",
    "fig.text(0.5, 0.04, 'Time', ha='center', va='center')\n",
    "fig.text(0.06, 0.5, 'Conversion', ha='center', va='center', rotation='vertical')\n",
    "fig.suptitle(\"Support Vector Regression Model\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameter for grid search\n",
    "kernel = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "gamma = ['scale', 'auto']\n",
    "C = [0.1, 1, 10, 100, 1000]\n",
    "epsilon = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "degree = [2, 3, 4, 5]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'kernel': kernel,\n",
    "               'gamma': gamma,\n",
    "               'C': C,\n",
    "               'epsilon': epsilon,\n",
    "               'degree': degree}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the random grid to search for best hyperparameters\n",
    "# Create the grid search model and fit to the training data\n",
    "#svr_grid_search = GridSearchCV(SVR(), param_grid=param_grid, verbose = 3, n_jobs=-1, cv = 3,\n",
    "                                scoring = 'neg_mean_absolute_error')\n",
    "#svr_grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Random search of parameters, using 4 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "svr_random = RandomizedSearchCV(SVR(), param_distributions=param_grid,\n",
    "                              n_iter = 2, scoring='neg_mean_absolute_error', \n",
    "                              cv = 4, verbose=3, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "svr_random.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
