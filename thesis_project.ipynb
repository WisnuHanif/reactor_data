{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Running_cycle</th>\n",
       "      <th>FI-001</th>\n",
       "      <th>FI-002</th>\n",
       "      <th>TC-001</th>\n",
       "      <th>TC-002</th>\n",
       "      <th>DT-001</th>\n",
       "      <th>DT-002</th>\n",
       "      <th>DP-001</th>\n",
       "      <th>DP-002</th>\n",
       "      <th>...</th>\n",
       "      <th>TI-034</th>\n",
       "      <th>TI-035</th>\n",
       "      <th>TI-036</th>\n",
       "      <th>TI-037</th>\n",
       "      <th>TI-038</th>\n",
       "      <th>TI-039</th>\n",
       "      <th>TI-040</th>\n",
       "      <th>TI-041</th>\n",
       "      <th>TI-042</th>\n",
       "      <th>CONVERSION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6/29/2004 4:00</td>\n",
       "      <td>1</td>\n",
       "      <td>57.376325</td>\n",
       "      <td>669.985139</td>\n",
       "      <td>319.496265</td>\n",
       "      <td>270.298088</td>\n",
       "      <td>68.159380</td>\n",
       "      <td>42.059748</td>\n",
       "      <td>16.935505</td>\n",
       "      <td>0.967330</td>\n",
       "      <td>...</td>\n",
       "      <td>308.465166</td>\n",
       "      <td>293.210571</td>\n",
       "      <td>288.108362</td>\n",
       "      <td>312.395056</td>\n",
       "      <td>305.310342</td>\n",
       "      <td>303.123348</td>\n",
       "      <td>310.085243</td>\n",
       "      <td>309.464836</td>\n",
       "      <td>308.546075</td>\n",
       "      <td>93.200705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/29/2004 4:00</td>\n",
       "      <td>2</td>\n",
       "      <td>57.415584</td>\n",
       "      <td>670.175315</td>\n",
       "      <td>319.506829</td>\n",
       "      <td>270.557335</td>\n",
       "      <td>68.149101</td>\n",
       "      <td>43.819212</td>\n",
       "      <td>16.906026</td>\n",
       "      <td>0.974280</td>\n",
       "      <td>...</td>\n",
       "      <td>310.060319</td>\n",
       "      <td>294.679554</td>\n",
       "      <td>289.054518</td>\n",
       "      <td>314.409080</td>\n",
       "      <td>307.335927</td>\n",
       "      <td>304.765668</td>\n",
       "      <td>311.408695</td>\n",
       "      <td>310.634102</td>\n",
       "      <td>309.389468</td>\n",
       "      <td>93.128145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/29/2004 4:00</td>\n",
       "      <td>3</td>\n",
       "      <td>57.454843</td>\n",
       "      <td>670.365491</td>\n",
       "      <td>319.517393</td>\n",
       "      <td>270.816583</td>\n",
       "      <td>68.138821</td>\n",
       "      <td>45.578677</td>\n",
       "      <td>16.876548</td>\n",
       "      <td>0.981229</td>\n",
       "      <td>...</td>\n",
       "      <td>311.655473</td>\n",
       "      <td>296.148536</td>\n",
       "      <td>290.000675</td>\n",
       "      <td>316.423104</td>\n",
       "      <td>309.361511</td>\n",
       "      <td>306.407989</td>\n",
       "      <td>312.732147</td>\n",
       "      <td>311.803369</td>\n",
       "      <td>310.232862</td>\n",
       "      <td>93.055586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/30/2004 0:00</td>\n",
       "      <td>4</td>\n",
       "      <td>57.543094</td>\n",
       "      <td>670.622632</td>\n",
       "      <td>319.553869</td>\n",
       "      <td>271.363961</td>\n",
       "      <td>68.380253</td>\n",
       "      <td>49.568133</td>\n",
       "      <td>16.811533</td>\n",
       "      <td>1.000760</td>\n",
       "      <td>...</td>\n",
       "      <td>315.280320</td>\n",
       "      <td>299.371886</td>\n",
       "      <td>292.082630</td>\n",
       "      <td>320.951668</td>\n",
       "      <td>313.762146</td>\n",
       "      <td>309.971053</td>\n",
       "      <td>315.635902</td>\n",
       "      <td>314.406282</td>\n",
       "      <td>312.107740</td>\n",
       "      <td>92.830864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/30/2004 0:00</td>\n",
       "      <td>5</td>\n",
       "      <td>57.470024</td>\n",
       "      <td>670.828064</td>\n",
       "      <td>319.515243</td>\n",
       "      <td>270.964477</td>\n",
       "      <td>67.735901</td>\n",
       "      <td>45.934814</td>\n",
       "      <td>16.879419</td>\n",
       "      <td>0.977966</td>\n",
       "      <td>...</td>\n",
       "      <td>312.047943</td>\n",
       "      <td>296.581512</td>\n",
       "      <td>290.251892</td>\n",
       "      <td>316.915100</td>\n",
       "      <td>309.949554</td>\n",
       "      <td>306.832458</td>\n",
       "      <td>313.039825</td>\n",
       "      <td>312.000702</td>\n",
       "      <td>310.427032</td>\n",
       "      <td>93.200151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Time  Running_cycle     FI-001      FI-002      TC-001  \\\n",
       "0  6/29/2004 4:00              1  57.376325  669.985139  319.496265   \n",
       "1  6/29/2004 4:00              2  57.415584  670.175315  319.506829   \n",
       "2  6/29/2004 4:00              3  57.454843  670.365491  319.517393   \n",
       "3  6/30/2004 0:00              4  57.543094  670.622632  319.553869   \n",
       "4  6/30/2004 0:00              5  57.470024  670.828064  319.515243   \n",
       "\n",
       "       TC-002     DT-001     DT-002     DP-001    DP-002  ...      TI-034  \\\n",
       "0  270.298088  68.159380  42.059748  16.935505  0.967330  ...  308.465166   \n",
       "1  270.557335  68.149101  43.819212  16.906026  0.974280  ...  310.060319   \n",
       "2  270.816583  68.138821  45.578677  16.876548  0.981229  ...  311.655473   \n",
       "3  271.363961  68.380253  49.568133  16.811533  1.000760  ...  315.280320   \n",
       "4  270.964477  67.735901  45.934814  16.879419  0.977966  ...  312.047943   \n",
       "\n",
       "       TI-035      TI-036      TI-037      TI-038      TI-039      TI-040  \\\n",
       "0  293.210571  288.108362  312.395056  305.310342  303.123348  310.085243   \n",
       "1  294.679554  289.054518  314.409080  307.335927  304.765668  311.408695   \n",
       "2  296.148536  290.000675  316.423104  309.361511  306.407989  312.732147   \n",
       "3  299.371886  292.082630  320.951668  313.762146  309.971053  315.635902   \n",
       "4  296.581512  290.251892  316.915100  309.949554  306.832458  313.039825   \n",
       "\n",
       "       TI-041      TI-042  CONVERSION  \n",
       "0  309.464836  308.546075   93.200705  \n",
       "1  310.634102  309.389468   93.128145  \n",
       "2  311.803369  310.232862   93.055586  \n",
       "3  314.406282  312.107740   92.830864  \n",
       "4  312.000702  310.427032   93.200151  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing research data\n",
    "https://github.com/WisnuHanif/reactor_data/blob/main/reactor_data.csv'\n",
    "prep0 = pd.read_csv('https://raw.githubusercontent.com/WisnuHanif/reactor_data/main/reactor_data.csv')\n",
    "prep0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Time', 'Running_cycle', 'FI-001', 'FI-002', 'TC-001', 'TC-002',\n",
       "       'DT-001', 'DT-002', 'DP-001', 'DP-002', 'DP-003', 'DP-004', 'PI-001',\n",
       "       'PI-002', 'PI-003', 'PI-004', 'AI-001', 'AI-002', 'AI-003', 'AI-004',\n",
       "       'AI-005', 'AI-006', 'AI-007', 'AI-008', 'AI-009', 'AI-010', 'RX-001',\n",
       "       'TI-001', 'TI-002', 'TI-005', 'TI-006', 'TI-007', 'TI-008', 'TI-009',\n",
       "       'TI-010', 'TI-011', 'TI-012', 'TI-013', 'TI-014', 'TI-015', 'TI-018',\n",
       "       'TI-019', 'TI-020', 'TI-021', 'TI-022', 'TI-023', 'TI-024', 'TI-025',\n",
       "       'TI-026', 'TI-027', 'TI-028', 'TI-029', 'TI-030', 'TI-031', 'TI-032',\n",
       "       'TI-033', 'TI-034', 'TI-035', 'TI-036', 'TI-037', 'TI-038', 'TI-039',\n",
       "       'TI-040', 'TI-041', 'TI-042', 'CONVERSION'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Identity variables name\n",
    "prep0.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION, CLEANING, AND FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing variable description & 'NO', 'Time' column\n",
    "#prep1 = prep0.iloc[1:, :].drop(['Running_cycle','Time'], axis=1)\n",
    "prep1 = prep0.iloc[:, :].drop(['FI-001','Running_cycle','Time'], axis=1)\n",
    "prep1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert timestamp object data to numerical\n",
    "prep2 = prep1.apply(pd.to_numeric)\n",
    "print(prep2.dtypes, prep2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there's missing value\n",
    "prep2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing data where plant is not run, by identifying total raw material 'FI-001' loss flow rate\n",
    "sns.boxplot(data=prep2,x=prep2['FI-002'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove shut down data by identifying outlier FI-001 with Inter Quantile Range Method\n",
    "\n",
    "from numpy import percentile\n",
    "# calculate interquartile range\n",
    "q25_a, q75_a = percentile(prep2['FI-002'], 25), percentile(prep2['FI-002'], 75)\n",
    "iqr_a = q75_a - q25_a\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25_a, q75_a, iqr_a))\n",
    "# calculate the outlier cutoff\n",
    "cut_off_a = iqr_a * 1.5\n",
    "lower_a, upper_a = q25_a - cut_off_a, q75_a + cut_off_a\n",
    "print('Lower whisker=%.2f, Upper whisker=%.2f' % (lower_a, upper_a))\n",
    "# identify outliers\n",
    "shut_down_data = prep2[(prep2['FI-002']<lower_a)|(prep2['FI-002']>upper_a)]\n",
    "print('Shut down data: %d' % len(shut_down_data))\n",
    "# remove outliers\n",
    "shut_down_removed = prep2[(prep2['FI-002']>lower_a)&(prep2['FI-002']<upper_a)]\n",
    "print('Non-Shut down data: %d' % len(shut_down_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check again if there's still outlier in 'FI-001'\n",
    "sns.boxplot(data=shut_down_removed, x=shut_down_removed['FI-002'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep3 = shut_down_removed\n",
    "prep3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outlier for all variables while keeps the whole row intact\n",
    "lb = prep3.quantile(0.01)\n",
    "ub = prep3.quantile(0.99)\n",
    "\n",
    "prep4 = prep3[(prep3 > lb) & (prep3 < ub)]\n",
    "prep4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check deleted value position\n",
    "import missingno as mno\n",
    "mno.matrix(prep4, figsize = (20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Correlation matrix between variables before missing value imputation\n",
    "#corr = prep4.corr()\n",
    "#corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr.values[np.triu_indices_from(corr.values,1)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing value (from removed outlier) with imputer\n",
    "prep5 = prep4.interpolate(method ='linear', limit_direction ='forward')\n",
    "prep5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep5.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep5.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Correlation matrix after data imputation\n",
    "corr2 = prep5.corr()\n",
    "corr2.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization plot for all variables\n",
    "#group_1 = prep5.iloc[:,0:9]\n",
    "#group_2 = prep5.iloc[:,9:18]\n",
    "#group_3 = prep5.iloc[:,18:27]\n",
    "#group_4 = prep5.iloc[:,27:36]\n",
    "#group_5 = prep5.iloc[:,36:45]\n",
    "#group_6 = prep5.iloc[:,45:54]\n",
    "#group_7 = prep5.iloc[:,54:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plot for group 1\n",
    "#group_1.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 2\n",
    "#group_2.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 3\n",
    "#group_3.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 4\n",
    "#group_4.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 5\n",
    "#group_5.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 6\n",
    "#group_6.plot(subplots =True, sharex = True, figsize = (30,80))\n",
    "#Plot for group 7\n",
    "#group_7.plot(subplots =True, sharex = True, figsize = (40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson correlation coefficient\n",
    "select_corr = prep5.corr()[\"CONVERSION\"].sort_values(ascending=False)[1:]\n",
    "\n",
    "# absolute for positive values\n",
    "abs_corr = abs(select_corr)\n",
    "\n",
    "# random threshold for features to keep\n",
    "selected_features = abs_corr[abs_corr>0.4]\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop low correlation features\n",
    "prep6 = prep5[selected_features.index].interpolate(method ='linear', limit_direction ='backward')\n",
    "prep6.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_lasso = prep5[\"CONVERSION\"]\n",
    "X_lasso = prep6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove collinearity by removing irrelavant features with ebbedded method\n",
    "from sklearn.linear_model import LassoCV\n",
    "reg = LassoCV()\n",
    "reg.fit(X_lasso, y_lasso)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % reg.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %reg.score(X_lasso,y_lasso))\n",
    "coef = pd.Series(reg.coef_, index = X_lasso.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize important feature\n",
    "imp_coef = coef.sort_values()\n",
    "plt.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select relevant reatures\n",
    "abs_coef = abs(coef)\n",
    "relevant_features = abs_coef[abs_coef>0]\n",
    "prep7 = prep6[relevant_features.index].sort_index(axis=1, ascending=True)\n",
    "#prep7 = X_lasso\n",
    "prep7['CONVERSION'] = prep5[\"CONVERSION\"]\n",
    "#prep7['CONVERSION'] = y_lasso\n",
    "prep7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing correlation between relevant features\n",
    "corr3 = prep7.corr().style.background_gradient(cmap='coolwarm')\n",
    "corr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop high correlation variables among predictor\n",
    "prep7 = prep7.drop(['TI-007','TI-011', 'TI-014'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Scaling with normalization\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "scaled_data = pd.DataFrame(scaler.fit_transform(prep7), columns = prep7.columns)\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select data for predictors and target\n",
    "\n",
    "#Import the features\n",
    "X_df = scaled_data.drop('CONVERSION', axis = 1)\n",
    "X = scaled_data.drop('CONVERSION', axis = 1).values.astype(float).reshape(-1, len(scaled_data.columns)-1)\n",
    "\n",
    "# Extract the target\n",
    "y_df = scaled_data['CONVERSION']\n",
    "y = scaled_data['CONVERSION'].values.astype(float)\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to return conversion scale for later use\n",
    "def return_conversion_scale(variable_plot):\n",
    "    minimum = min(prep7['CONVERSION'])\n",
    "    maximum = max(prep7['CONVERSION'])\n",
    "    return ((variable_plot - min(variable_plot)) /(max(variable_plot) - min(variable_plot)))*(maximum-minimum)+minimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide data into training 70%, validation 15% and testing 15%\n",
    "#In this first step, we will divide data which will be used to train the model and as prediction\n",
    "#1st splitting : training (85%); testing (15%)\n",
    "y_tr_size = int(len(y) * 0.85)\n",
    "y_tr, y_test = y[0:y_tr_size], y[y_tr_size:len(y)]\n",
    "X_tr_size = int(len(X) * 0.85)\n",
    "X_tr, X_test = X[0:X_tr_size], X[X_tr_size:len(X)]\n",
    "print('Observations: %d' % (len(y)))\n",
    "print('Training Observations: %d' % (len(y_tr)))\n",
    "print('Testing Observations: %d' % (len(y_test)))\n",
    "plt.subplots(figsize=(8,4))\n",
    "plt.plot(y_tr)\n",
    "plt.plot([None for i in y_tr] + [X for X in y_test])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', X_tr.shape)\n",
    "print('Training Targets Shape:', X_test.shape)\n",
    "print('Testing Features Shape:', y_tr.shape)\n",
    "print('Testing Targets Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and initialize the cross-validation iterator\n",
    "#In the second step, we split training data from 1st step into training (80%); validation (20%)\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "n_splits = 5\n",
    "ts_split = TimeSeriesSplit(n_splits)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "for ii, (tr, tt) in enumerate(ts_split.split(X_tr, y_tr)):\n",
    "    \n",
    "    #Plot training and testing indices\n",
    "    l1 = ax.scatter(tr, [ii] * len(tr), c=[plt.cm.coolwarm(.1)],\n",
    "                    marker='_', lw=15)\n",
    "    l2 = ax.scatter(tt, [ii] * len(tt), c=[plt.cm.coolwarm(.9)],\n",
    "                    marker='_', lw=15)\n",
    "    ax.set(ylim=[n_splits, -.2], yticks=np.arange(n_splits), title='TimeSeriesSplit Behavior', xlabel='Data index', ylabel='CV iteration')\n",
    "    ax.legend([l1, l2], ['Training', 'Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in ts_split.split(X_tr, y_tr):\n",
    "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "     #To get the indices \n",
    "     X_train, X_val = X_tr[train_index], X_tr[test_index]\n",
    "     y_train, y_val = y_tr[train_index], y_tr[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', X_train.shape)\n",
    "print('Training Targets Shape:', y_train.shape)\n",
    "print('Validation Features Shape:', X_val.shape)\n",
    "print('Validation Targets Shape:', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measurement metrics for inverted scale\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from math import log\n",
    "    \n",
    "def model_metrics(actual, predict):\n",
    "    ac = return_conversion_scale(actual)\n",
    "    pr = return_conversion_scale(predict)\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(ac, pr))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(ac, pr))\n",
    "    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(ac, pr)))\n",
    "    print('Coefficient of Determination:', r2_score(ac, pr)) \n",
    "    \n",
    "    # calculate aic for regression\n",
    "    lr_model = LinearRegression()\n",
    "    lr_model.fit(pr.reshape(-1, 1), ac.reshape(-1, 1))\n",
    "    # number of parameters\n",
    "    num_params = len(lr_model.coef_) + 1\n",
    "    # predict the training set\n",
    "    yhat = lr_model.predict(pr.reshape(-1, 1))\n",
    "    # calculate the error\n",
    "    mse = metrics.mean_squared_error(ac, yhat)\n",
    "    # calculate the aic\n",
    "    aic = len(ac) * log(mse) + 2 * num_params\n",
    "    print('Akaike Information Criterion: %.3f' % aic)\n",
    "    \n",
    "    # calculate bic for regression\n",
    "    bic = len(ac) * log(mse) + num_params * log(len(ac))\n",
    "    print('Bayesian Information Criterion: %.3f' % bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING MODEL : RANDOM FORREST REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = list(X_df.columns)\n",
    "feature_names = X_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Ramdom Forest Regressor without hyper parameter tuning (default)\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, oob_score = True)\n",
    "regressor.fit(X_train, y_train) # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate Regressor score and OOB Score of the model\n",
    "#print(\"\\nRegressor Score \" + str(regressor.score(X_train, y_train)), \"\\nOOB Score \" + str(regressor.oob_score_)) # change this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_model_pred = regressor.predict(X_val)\n",
    "rfr_model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "model_metrics(y_val, rfr_model_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_targets = test_targets.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs prediction\n",
    "with plt.style.context('default'):\n",
    "    plt.figure()\n",
    "    plt.subplots(figsize=(8,4))\n",
    "    plt.plot(return_conversion_scale(y_val), label = \"Actual Conversion\")\n",
    "    plt.plot(return_conversion_scale(rfr_model_pred), label = \"Prediction\")\n",
    "    plt.grid()\n",
    "    plt.title('Random Forrest Regression Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Conversion (%)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = pd.DataFrame({'feature': feature_list,\n",
    "                   'importance': regressor.feature_importances_}).\\\n",
    "                    sort_values('importance', ascending = False)\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Search with Cross Validation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 10, stop = 200, num = 39)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid,\n",
    "                              n_iter = 100, scoring='neg_mean_squared_error', \n",
    "                              cv = ts_split, verbose=2, n_jobs=-1,\n",
    "                              return_train_score=True)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_random = rf_random.best_estimator_\n",
    "best_pred = best_random.predict(X_val)\n",
    "best_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Best Random Search Model\n",
    "\n",
    "model_metrics(y_val, best_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = pd.DataFrame(rf_random.cv_results_).sort_values(by=['rank_test_score'])\n",
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs prediction\n",
    "with plt.style.context('default'):\n",
    "    plt.figure()\n",
    "    plt.subplots(figsize=(8,4))\n",
    "    plt.plot(return_conversion_scale(y_val), label = \"Actual Conversion\")\n",
    "    plt.plot(return_conversion_scale(best_pred), label = \"Prediction\")\n",
    "    plt.grid()\n",
    "    plt.title('Random Forrest Regression Prediction (Best Parameter Tuning)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Conversion (%)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Curves\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "tree_grid = {'n_estimators': [int(x) for x in np.linspace(start = 10, stop = 200, num = 39)]}\n",
    "\n",
    "# Create the grid search model and fit to the training data\n",
    "tree_grid_search = GridSearchCV(best_random, param_grid=tree_grid, verbose = 3, n_jobs=-1, cv = ts_split,\n",
    "                                scoring = 'neg_mean_absolute_error')\n",
    "tree_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = pd.DataFrame(rf_random.cv_results_)\n",
    "train_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(model, param = 'n_estimators', name = 'Num Trees'):\n",
    "    param_name = 'param_%s' % param\n",
    "\n",
    "    # Extract information from the cross validation model\n",
    "    #train_scores = model.cv_results_['mean_train_score']\n",
    "    test_scores = model.cv_results_['mean_test_score']\n",
    "    train_time = model.cv_results_['mean_fit_time']\n",
    "    param_values = list(model.cv_results_[param_name])\n",
    "    \n",
    "    # Plot the scores over the parameter\n",
    "    plt.subplots(1, 2, figsize=(10, 6))\n",
    "    plt.subplot(121)\n",
    "    #plt.plot(param_values, train_scores, 'bo-', label = 'train')\n",
    "    plt.plot(param_values, test_scores, 'go-', label = 'test')\n",
    "    plt.ylim(ymin = -0.2, ymax = 0)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Neg Mean Absolute Error')\n",
    "    plt.title('Score vs %s' % name)\n",
    "    \n",
    "    plt.subplot(122)\n",
    "    plt.plot(param_values, train_time, 'ro-')\n",
    "    plt.ylim(ymin = 0.0, ymax = 10.0)\n",
    "    plt.grid()\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel('Train Time (sec)')\n",
    "    plt.title('Training Time vs %s' % name)\n",
    "    \n",
    "    plt.tight_layout(pad = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(tree_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFR_final = rf_random\n",
    "RFR_predict = RFR_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#measure model performance\n",
    "model_metrics(y_test, RFR_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs prediction\n",
    "with plt.style.context('default'):\n",
    "    plt.figure()\n",
    "    plt.subplots(figsize=(8,4))\n",
    "    plt.plot(return_conversion_scale(y_test), label = \"Actual Conversion\")\n",
    "    plt.plot(return_conversion_scale(RFR_predict), label = \"Prediction\")\n",
    "    plt.grid()\n",
    "    plt.title('Random Forrest Regression Prediction (Best Parameter Tuning)')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Conversion (%)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING MODEL : SUPPORT VECTOR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR()\n",
    "svr_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_pred = svr_rbf.predict(X_val)\n",
    "svr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating SVR performance\n",
    "model_metrics(y_val, svr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs prediction\n",
    "with plt.style.context('default'):\n",
    "    plt.figure()\n",
    "    plt.subplots(figsize=(8,4))\n",
    "    plt.plot(return_conversion_scale(y_val), label = \"Actual Conversion\")\n",
    "    plt.plot(return_conversion_scale(svr_pred), label = \"Prediction\")\n",
    "    plt.grid()\n",
    "    plt.title('Support Vector Regression Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Conversion (%)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVR polynomial kernel with 3 degree\n",
    "#svr_poly3 = SVR(kernel='poly', gamma='auto', degree=3)\n",
    "#SVR polynomial kernel with 4 degree\n",
    "#svr_poly4 = SVR(kernel='poly', gamma='auto', degree=4)\n",
    "#SVR polynomial kernel with 5 degree\n",
    "#svr_poly5 = SVR(kernel='poly', gamma='auto', degree=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#svrs = [svr_rbf, svr_poly3, svr_poly4, svr_poly5]\n",
    "#kernel_label = ['rbf', '3 degree Polynomial', '4 degree Polynomial', '5 degree Polynomial']\n",
    "#fig, axes = plt.subplots(nrows=4, ncols=1, figsize=(10, 10), sharey=True)\n",
    "#for ix, svr in enumerate(svrs):\n",
    "#    svr.fit(X_train, y_train)\n",
    "#    svr_poly_pred = svr.predict(X_val)\n",
    "#    print('Mean Absolute Error:', metrics.mean_absolute_error(y_val, svr_poly_pred))\n",
    "#    print('Mean Squared Error:', metrics.mean_squared_error(y_val, svr_poly_pred))\n",
    "#    print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_val, svr_poly_pred)))\n",
    "#    print('Coefficient of Determination:', r2_score(y_val, svr_poly_pred)) \n",
    "#    with plt.style.context('ggplot'):\n",
    "#        axes[ix].plot(y_val, label = \"Actual Conversion\")\n",
    "#        axes[ix].plot(svr_poly_pred,\n",
    "#                  label='{} model'.format(kernel_label[ix]))\n",
    "#        axes[ix].legend(loc='upper center', bbox_to_anchor=(0.5, 1.1),\n",
    "#                    ncol=1, fancybox=True, shadow=True)\n",
    "#        axes[ix].legend(loc='best')\n",
    "#fig.text(0.5, 0.04, 'Time', ha='center', va='center')\n",
    "#fig.text(0.06, 0.5, 'Conversion', ha='center', va='center', rotation='vertical')\n",
    "#fig.suptitle(\"Support Vector Regression Model\", fontsize=14)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set parameter for grid search : 1st round\n",
    "kernel = ['poly', 'rbf', 'sigmoid']\n",
    "degree = [2, 3, 4, 5]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'kernel': kernel,\n",
    "               'degree': degree}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the random grid to search for best hyperparameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the grid search model and fit to the training data\n",
    "svr_grid_first = GridSearchCV(SVR(), param_grid=param_grid, verbose = 3, n_jobs=-1, cv = ts_split,\n",
    "                                scoring = 'neg_mean_absolute_error')\n",
    "svr_grid_first.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_grid_first.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_first = svr_grid_first.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search to find best hyperparameters : 2nd round\n",
    "gamma = ['scale', 'auto']\n",
    "C = [0.001, 0.01, 0.1, 1, 10]\n",
    "epsilon = [0.0001, 0.001, 0.01, 0.1]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid_final = {'gamma': gamma,\n",
    "               'C': C,\n",
    "               'epsilon': epsilon}\n",
    "\n",
    "# Create the grid search model and fit to the training data\n",
    "svr_grid_final = GridSearchCV(best_grid_first, param_grid=param_grid_final, verbose = 3, n_jobs=-1, cv = ts_split,\n",
    "                                scoring = 'neg_mean_absolute_error')\n",
    "svr_grid_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_grid_final.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict hyper parameter tuned SVR\n",
    "best_svr_pred = svr_grid_final.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating hyper parameter tuned SVR performance\n",
    "\n",
    "model_metrics(y_val, best_svr_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs prediction\n",
    "with plt.style.context('default'):\n",
    "    plt.figure()\n",
    "    plt.subplots(figsize=(8,4))\n",
    "    plt.plot(return_conversion_scale(y_val), label = \"Actual Conversion\")\n",
    "    plt.plot(return_conversion_scale(best_svr_pred), label = \"Prediction\")\n",
    "    plt.grid()\n",
    "    plt.title('Support Vector Regression Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Conversion (%)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing the final model \n",
    "SVR_final = svr_grid_final\n",
    "SVR_predict = SVR_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating final model SVR performance\n",
    "\n",
    "model_metrics(y_test, SVR_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs prediction\n",
    "with plt.style.context('default'):\n",
    "    plt.figure()\n",
    "    plt.subplots(figsize=(8,4))\n",
    "    plt.plot(return_conversion_scale(y_test), label = \"Actual Conversion\")\n",
    "    plt.plot(return_conversion_scale(SVR_predict), label = \"Prediction\")\n",
    "    plt.grid()\n",
    "    plt.title('Support Vector Regression Prediction')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Conversion (%)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_rbf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN - LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import RNN-LSTM library\n",
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape input\n",
    "X_train_adj = X_train.reshape((X_train.shape[0], 1, X_train.shape[1])) #reshape (adjust) train shape to 3 dimensional\n",
    "X_val_adj  = X_val.reshape((X_val.shape[0], 1, X_val.shape[1])) #reshape (adjust) test shape to 3 dimensional\n",
    "print(X_train_adj.shape, X_val_adj.shape, y_train.shape, y_val.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the model\n",
    "model_lstm = tf.keras.Sequential()\n",
    "model_lstm.add(tf.keras.layers.LSTM(75, return_sequences = True, input_shape = (X_train_adj.shape[1], X_train_adj.shape[2])))\n",
    "model_lstm.add(tf.keras.layers.LSTM(units=30))\n",
    "model_lstm.add(tf.keras.layers.Dropout(0.2))\n",
    "model_lstm.add(tf.keras.layers.Dense(units=1))\n",
    "model_lstm.compile(loss = 'mse', optimizer = 'adam')\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "history_lstm = model_lstm.fit(X_train_adj, y_train, epochs = 100, batch_size=10, validation_data = (X_val_adj, y_val), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history_lstm.history['loss'], label='train')\n",
    "plt.plot(history_lstm.history['val_loss'], label='test')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_first_pred = model_lstm(X_val_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Tensor value to array\n",
    "lstm_first_pred_a = lstm_first_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics(y_val, lstm_first_pred_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot actual vs prediction\n",
    "with plt.style.context('default'):\n",
    "    plt.figure()\n",
    "    plt.subplots(figsize=(8,4))\n",
    "    plt.plot(return_conversion_scale(y_val), label = \"Actual Conversion\")\n",
    "    plt.plot(return_conversion_scale(lstm_first_pred), label = \"Prediction\")\n",
    "    plt.grid()\n",
    "    plt.title('LSTM')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Conversion (%)')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create LSTM function model\n",
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.LSTM(75, return_sequences = True, input_shape = (X_train_adj.shape[1], X_train_adj.shape[2])))\n",
    "    model.add(tf.keras.layers.LSTM(units=30))\n",
    "    model.add(tf.keras.layers.Dropout(0.2))\n",
    "    model.add(tf.keras.layers.Dense(units=1))\n",
    "    \n",
    "    model.compile(loss = 'mse', optimizer = 'adam', metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tuning = KerasRegressor(build_fn=create_model, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [32, 64, 128, 256]\n",
    "epochs = [10, 20, 50, 100, 1000]\n",
    "\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "lstm_grid = GridSearchCV(estimator=model_tuning, param_grid=param_grid, n_jobs=-1, cv=ts_split)\n",
    "grid_result = lstm_grid.fit(X_train_adj, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_result.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lstm = grid_result.best_estimator_\n",
    "tune_predict = best_lstm.predict(X_val_adj)\n",
    "model_metrics(y_val, tune_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
