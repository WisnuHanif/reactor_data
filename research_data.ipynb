{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing research data\n",
    "#url = 'https://github.com/WisnuHanif/reactor_data/blob/main/reactor_data.csv'\n",
    "prep0 = pd.read_csv('https://raw.githubusercontent.com/WisnuHanif/reactor_data/main/reactor_data.csv')\n",
    "prep0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identity variables name\n",
    "prep0.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing variable description & 'NO', 'Time' column\n",
    "prep1 = prep0.iloc[1:, :].drop(['Running_cycle','Time'], axis=1)\n",
    "prep1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert timestamp object data to numerical\n",
    "prep2 = prep1.apply(pd.to_numeric)\n",
    "print(prep2.dtypes, prep2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if there's missing value\n",
    "prep2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing data where plant is not run, by identifying total raw material 'FI-001' loss flow rate\n",
    "import seaborn as sns\n",
    "sns.boxplot(data=prep2,x=prep2['FI-001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove shut down data by identifying outlier FI-001 with Inter Quantile Range Method\n",
    "\n",
    "from numpy import percentile\n",
    "# calculate interquartile range\n",
    "q25_a, q75_a = percentile(prep2['FI-001'], 25), percentile(prep2['FI-001'], 75)\n",
    "iqr_a = q75_a - q25_a\n",
    "print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25_a, q75_a, iqr_a))\n",
    "# calculate the outlier cutoff\n",
    "cut_off_a = iqr_a * 1.5\n",
    "lower_a, upper_a = q25_a - cut_off_a, q75_a + cut_off_a\n",
    "print('Lower whisker=%.2f, Upper whisker=%.2f' % (lower_a, upper_a))\n",
    "# identify outliers\n",
    "shut_down_data = prep2[(prep2['FI-001']<lower_a)|(prep2['FI-001']>upper_a)]\n",
    "print('Shut down data: %d' % len(shut_down_data))\n",
    "# remove outliers\n",
    "shut_down_removed = prep2[(prep2['FI-001']>lower_a)&(prep2['FI-001']<upper_a)]\n",
    "print('Non-Shut down data: %d' % len(shut_down_removed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check again if there's still outlier in 'FI-001'\n",
    "sns.boxplot(data=shut_down_removed, x=shut_down_removed['FI-001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep3 = shut_down_removed\n",
    "prep3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outlier for all variables while keeps the whole row intact\n",
    "lb = prep3.quantile(0.01)\n",
    "ub = prep3.quantile(0.99)\n",
    "\n",
    "prep4 = prep3[(prep3 > lb) & (prep3 < ub)]\n",
    "prep4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check deleted value position\n",
    "import missingno as mno\n",
    "mno.matrix(prep4, figsize = (20, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Correlation matrix between variables before missing value imputation\n",
    "corr = prep4.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.values[np.triu_indices_from(corr.values,1)].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing value (from removed outlier) with imputer\n",
    "prep5 = prep4.interpolate(method ='linear', limit_direction ='backward')\n",
    "prep5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(120, 60))\n",
    "#heatmap = sns.heatmap(prep3.corr(), vmin=-1, vmax=1, annot=True, cmap='coolwarm')\n",
    "#heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep5.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep4.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization plot for all variables\n",
    "group_1 = prep5.iloc[0:4000,0:10]\n",
    "group_2 = prep5.iloc[0:4000,10:20]\n",
    "group_3 = prep5.iloc[0:4000,20:30]\n",
    "group_4 = prep5.iloc[0:4000:,30:40]\n",
    "group_5 = prep5.iloc[0:4000:,40:50]\n",
    "group_6 = prep5.iloc[0:4000:,50:60]\n",
    "group_7 = prep5.iloc[0:4000:,60:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for group 1\n",
    "group_1.plot(subplots =True, sharex = True, figsize = (30,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for group 2\n",
    "group_2.plot(subplots =True, sharex = True, figsize = (30,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for group 3\n",
    "group_3.plot(subplots =True, sharex = True, figsize = (30,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for group 4\n",
    "group_4.plot(subplots =True, sharex = True, figsize = (30,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot for group 5\n",
    "group_5.plot(subplots =True, sharex = True, figsize = (30,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for group 6\n",
    "group_6.plot(subplots =True, sharex = True, figsize = (30,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for group 7\n",
    "group_7.plot(subplots =True, sharex = True, figsize = (40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.boxplot(prep5['FI-001'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corr2 = prep5.corr()\n",
    "corr2.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Scaling with normalization\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler()\n",
    "# transform data\n",
    "#scaled_data = pd.DataFrame(scaler.fit_transform(prep5), columns = prep5.columns)\n",
    "#print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataset after preparation and cleaning \n",
    "data = prep5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING MODEL : RANDOM FORREST REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "data.fillna(-999, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data for RamdomForrestRegressor\n",
    "\n",
    "#features = data.drop('CONVERSION', axis = 1).values.astype(float).reshape(-1, 63)\n",
    "#labels = data['CONVERSION'].values.astype(float)\n",
    "features = data.drop('CONVERSION', axis = 1)\n",
    "labels = data['CONVERSION']\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(data.drop('CONVERSION', axis = 1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
    "regressor.fit(train_features, train_labels)\n",
    "print(train_features.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(test_features)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate predictions\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(test_labels, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(test_labels, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(test_labels, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(y_pred - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING MODEL : SUPPORT VECTOR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# transform data\n",
    "svr_data = pd.DataFrame(scaler.fit_transform(data), columns = data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. import data for RamdomForrestRegressor\n",
    "\n",
    "x = svr_data.drop('CONVERSION', axis = 1).values.astype(float).reshape(-1, 63)\n",
    "y = svr_data['CONVERSION'].values.astype(float)\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Features Shape:', x_train.shape)\n",
    "print('Training Labels Shape:', y_train.shape)\n",
    "print('Testing Features Shape:', x_test.shape)\n",
    "print('Testing Labels Shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "SVRModel = SVR(kernel = 'rbf')\n",
    "SVRModel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_pred = SVRModel.predict(x_test)\n",
    "svr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating SVR performance\n",
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, svr_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, svr_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, svr_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
